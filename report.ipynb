{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "Gas Consumption in France\n",
    "2023-2024\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import yaml\n",
    "import glob\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import year,month,weekofyear\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder, Imputer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read some configurations from the yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    configuration = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'delimiter': '|'},\n",
       " {'schema': 'id_pdv int,cp int,pop string,latitude double,longitude  double,services string'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration['service_file_parameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark  = pyspark.sql.SparkSession.builder.appName(\"Gas\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Gas</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f89e42c7a60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Read the data from the csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the schema for the different datasets using the yaml configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the right delimiter for each each data from the configuration file\n",
    "gas_delimiter = configuration['gas_file_parameters'][0]['delimiter']\n",
    "station_delimiter = configuration['station_file_parameters'][0]['delimiter']\n",
    "service_delimiter = configuration['service_file_parameters'][0]['delimiter']\n",
    "\n",
    "#get the right schema for each data from the configuration file\n",
    "gas_schema = configuration['gas_file_parameters'][1]['schema']\n",
    "station_schema = configuration['station_file_parameters'][1]['schema']\n",
    "service_schema = configuration['service_file_parameters'][1]['schema']\n",
    "\n",
    "#collect the file data paths for each data from the configuration file\n",
    "gas_files = glob.glob(\"data/Prix*.csv\")\n",
    "station_files = glob.glob(\"data/Station*.csv\")\n",
    "service_files = glob.glob(\"data/Service*.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_ddf = spark.read.csv(gas_files, schema=gas_schema, sep=gas_delimiter)\n",
    "station_ddf = spark.read.csv(station_files, schema=station_schema, sep=station_delimiter)\n",
    "service_ddf = spark.read.csv(service_files, schema=service_schema, sep=service_delimiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the gas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+-------------------+-----------------+------------------+-----------------+-------------+------------------+\n",
      "|summary|             id_pdv|               cp|                pop|         latitude|         longitude|     id_carburant|nom_carburant|              prix|\n",
      "+-------+-------------------+-----------------+-------------------+-----------------+------------------+-----------------+-------------+------------------+\n",
      "|  count|           48873023|         48873024|           48873023|         48861413|          48861720|         48834162|     48834162|          48834162|\n",
      "|   mean|5.178747010046008E7|51777.70275334303|-18951.105633333333|4642316.448959652| 266430.0602396445|3.274674417470295|         NULL|1082.4760620455415|\n",
      "| stddev|2.688841715853314E7|26894.29038135437| 146411.93674099928|533857.2721312031|330934.95540068485|2.054033955455618|         NULL| 573.6996826572682|\n",
      "|    min|            1000001|                0|            -173935|   -2433288.11503|    -6841787.14211|                1|          E10|             0.001|\n",
      "|    max|           99999003|          4732853|                  R|    6260655.98007|     6178073.52057|                6|         SP98|            9999.0|\n",
      "+-------+-------------------+-----------------+-------------------+-----------------+------------------+-----------------+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gas_ddf.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48873026"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of observations\n",
    "gas_ddf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove missing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The removal rate of null observations is 0.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "c1 = gas_ddf.count()\n",
    "r = 100 * (c1 -  gas_ddf.dropna(how='any').count() ) / c1\n",
    "print(f\"The removal rate of null observations is {r:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new data without null observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_ddf = gas_ddf.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Preprocessing the Gas data </br>\n",
    "We will be doing the following :</br>\n",
    "* a) Sort date by date column\n",
    "* b) Split the date in year, month and weak of the year\n",
    "* c) Prepare latitude & longitude for mapping (divide by the right power of 10)\n",
    "* d) Create a Table associated with gas data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier we will use a preprocessing pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.a) Sort the date by date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_ddf = gas_ddf.sort(\"date\",ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+---------------+---------------+-------------------+------------+-------------+------+\n",
      "|  id_pdv|   cp|pop|       latitude|      longitude|               date|id_carburant|nom_carburant|  prix|\n",
      "+--------+-----+---+---------------+---------------+-------------------+------------+-------------+------+\n",
      "|76150002|76150|  A|4949456.8714207|99803.232277829|2008-01-01 00:00:00|           1|       Gazole|1190.0|\n",
      "|54300005|54300|  R|  4859064.54138|  642599.690486|2008-01-01 00:00:00|           1|       Gazole|1239.0|\n",
      "| 6250005| 6250|  R|      4358849.0|       703322.0|2008-01-01 00:00:00|           2|         SP95|1374.0|\n",
      "|54630001|54630|  A|      4860743.0|       617385.0|2008-01-01 00:00:00|           1|       Gazole|1239.0|\n",
      "|11700003|11700|  A|      4317816.0|       254421.0|2008-01-01 00:00:00|           2|         SP95|1469.0|\n",
      "+--------+-----+---+---------------+---------------+-------------------+------------+-------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gas_ddf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.b) Split the date in year, month and weak of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+---------------+---------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|  id_pdv|   cp|pop|       latitude|      longitude|               date|id_carburant|nom_carburant|  prix|year|month|weekofyear|\n",
      "+--------+-----+---+---------------+---------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|76150002|76150|  A|4949456.8714207|99803.232277829|2008-01-01 00:00:00|           1|       Gazole|1190.0|2008|    1|         1|\n",
      "|54300005|54300|  R|  4859064.54138|  642599.690486|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "| 6250005| 6250|  R|      4358849.0|       703322.0|2008-01-01 00:00:00|           2|         SP95|1374.0|2008|    1|         1|\n",
      "|54630001|54630|  A|      4860743.0|       617385.0|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "|11700003|11700|  A|      4317816.0|       254421.0|2008-01-01 00:00:00|           2|         SP95|1469.0|2008|    1|         1|\n",
      "+--------+-----+---+---------------+---------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gas_ddf = gas_ddf.withColumn(\"year\",year(gas_ddf.date))\n",
    "gas_ddf = gas_ddf.withColumn(\"month\",month(gas_ddf.date))\n",
    "gas_ddf = gas_ddf.withColumn(\"weekofyear\",weekofyear(gas_ddf.date))\n",
    "gas_ddf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.c) Prepare latitude & longitude for mapping (divide by the right power of 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+------------------+-----------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|  id_pdv|   cp|pop|          latitude|        longitude|               date|id_carburant|nom_carburant|  prix|year|month|weekofyear|\n",
      "+--------+-----+---+------------------+-----------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|76150002|76150|  A|   49.494568714207| 0.99803232277829|2008-01-01 00:00:00|           1|       Gazole|1190.0|2008|    1|         1|\n",
      "|54300005|54300|  R|48.590645413800004|6.425996904860001|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "| 6250005| 6250|  R|          43.58849|          7.03322|2008-01-01 00:00:00|           2|         SP95|1374.0|2008|    1|         1|\n",
      "|54630001|54630|  A|          48.60743|          6.17385|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "|11700003|11700|  A|          43.17816|          2.54421|2008-01-01 00:00:00|           2|         SP95|1469.0|2008|    1|         1|\n",
      "+--------+-----+---+------------------+-----------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gas_ddf = gas_ddf.withColumn(\"latitude\",F.col(\"latitude\")/100_000)\n",
    "gas_ddf = gas_ddf.withColumn(\"longitude\",F.col(\"longitude\")/100_000)\n",
    "gas_ddf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.d) Create a Table associated with gas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+------------------+-----------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|  id_pdv|   cp|pop|          latitude|        longitude|               date|id_carburant|nom_carburant|  prix|year|month|weekofyear|\n",
      "+--------+-----+---+------------------+-----------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|76150002|76150|  A|   49.494568714207| 0.99803232277829|2008-01-01 00:00:00|           1|       Gazole|1190.0|2008|    1|         1|\n",
      "|54300005|54300|  R|48.590645413800004|6.425996904860001|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "| 6250005| 6250|  R|          43.58849|          7.03322|2008-01-01 00:00:00|           2|         SP95|1374.0|2008|    1|         1|\n",
      "|54630001|54630|  A|          48.60743|          6.17385|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "|11700003|11700|  A|          43.17816|          2.54421|2008-01-01 00:00:00|           2|         SP95|1469.0|2008|    1|         1|\n",
      "+--------+-----+---+------------------+-----------------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gas_ddf.createOrReplaceTempView('gas')\n",
    "spark.sql(\"SELECT * FROM gas\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gas types have some interest for the rest of the project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+--------+\n",
      "|nom_carburant|   count|ratio(%)|\n",
      "+-------------+--------+--------+\n",
      "|       Gazole|16633159|   34.07|\n",
      "|          E10|10515716|   21.54|\n",
      "|         SP98|10197268|   20.89|\n",
      "|         SP95| 7122418|   14.59|\n",
      "|         GPLc| 2181898|    4.47|\n",
      "|          E85| 2173137|    4.45|\n",
      "+-------------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT nom_carburant,\n",
    "    count(*) as count,\n",
    "    round(100 * count(*) / (SELECT count(*) FROM gas),2) as `ratio(%)`\n",
    "    FROM gas \n",
    "    GROUP BY  nom_carburant\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, the representation of gas types, specifically **E85 and GPLc**, is notably lower. </br> Their individual ratio stands at approximately 5%, indicating a comparatively lower occurrence in our data.\n",
    "We will drop those gas types for next part of the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop gas types **E85 and GPLc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_ddf = gas_ddf.filter(\n",
    "    \"nom_carburant != 'GPLc' OR nom_carburant != 'E85'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Compute price index for each station per week:</br>\n",
    "Compute a new variable called “Price Index” for each gas type sold in\n",
    "a station such as:</br>\n",
    "\n",
    "$𝑷𝒓𝒊𝒄𝒆 𝑰𝒏𝒅𝒆𝒙 = 𝟏𝟎𝟎 × (\\frac{𝑫𝒂𝒚 𝑷𝒓𝒊𝒄𝒆 𝒊𝒏 𝒔𝒕𝒂𝒕𝒊𝒐𝒏 − 𝑨𝒗𝒆𝒓𝒂𝒈𝒆 𝑫𝒂𝒚 𝑷𝒓𝒊𝒄𝒆 𝒊𝒏 𝑭𝒓𝒂𝒏𝒄𝒆}{𝑨𝒗𝒆𝒓𝒂𝒈𝒆 𝑫𝒂𝒚 𝑷𝒓𝒊𝒄𝒆 𝒊𝒏 𝑭𝒓𝒂𝒏𝒄𝒆} + 𝟏)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:=====================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---+--------+---------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "|  id_pdv|   cp|pop|latitude|longitude|               date|id_carburant|nom_carburant|  prix|year|month|weekofyear|\n",
      "+--------+-----+---+--------+---------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "| 6250005| 6250|  R|43.58849|  7.03322|2008-01-01 00:00:00|           1|       Gazole|1239.0|2008|    1|         1|\n",
      "|11700003|11700|  A|43.17816|  2.54421|2008-01-01 00:00:00|           2|         SP95|1469.0|2008|    1|         1|\n",
      "+--------+-----+---+--------+---------+-------------------+------------+-------------+------+----+-----+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gas_ddf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
